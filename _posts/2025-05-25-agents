# Why are Agents so hot?

Agents are the hot topic of recent days? Why is that? The main use case for AI so far (at least till 2024 before chatbots 
got agentified with tools) was this type of assistant that helps you solve simple problems you throw at it. 
It is very knowledgeable but as soon as you ask it to do something that requires a bit of common sense and "googling" 
it fails miserably. Either making things up or providing inaccurate information. Let's take as an example trip planning

When asked to come up with itinerary with estimated budget for trip in a week we can expect AI will give us made up 
flights with price estimate unrelated to current price (and let's not dream about it finding best deal for us), 
types of attractions a list of most typical activities not necessarily available at the time of our trip and so on.
If we "digest it a little bit" and ask for specific season it will usually do a little better but still might recommend
things that were closed. I will later talk about how agentic approach addresses some of these issues.

More recently companies stated a goal of automating junior developers. Copilot etc. 
There was significant progress in this field. From AI having a hard time writing doc strings, 
through tests being written just based on test  docstring written by developer and interfaces and existing codebase, 
to most recently impressive improvements to existing algorithms and coming up with new ones EvolveAlpha [1](https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/). 
Last one being more about blend of evolutionary algorithms and ? but agentic concept that happened along the way and 
how they impacted the dynamic are still interesting.

Another interesting experiment was trying to Carnegie Mellon University was to build full fledge company with AI agents [2](https://the-agent-company.com/). Best models
didn't perform too well with best candidates being able to solve around 25% of given tasks but what I find most interesting are areas in which they struggled:
- Implicit understanding. When told to save results in a file with a “.docx” extension, the AI agents couldn’t make the logical leap that this meant creating a Microsoft Word document.
- Social skills and especially fluent collaboration.
- Web navigation, particularly dealing with pop-ups and complex user interfaces.
Above are easy for humans but we have to keep in mind that agents have a lot of advantages like being highly scalable, follow instructions well... or so people 
arguing for AI Agents say but in the study very human-like behavior emerged where: when faced with difficult tasks, the agents sometimes took shortcuts and then reported successful completion. 
While exposing limitations of current technology and brining expectation a bit more in-line with "everyone at work will be replaced by AI in a year" with AI integration
in the workplace that follows careful task selection, realistic expectations, and probably a good deal of human oversight we might soon experiencing the 6th wave of innovaiton in full swing [3](https://core.ac.uk/download/pdf/30907274.pdf).

Finally the most recent document released by Google proposing the concept of an independent "agentic contractor" 
and explaining how multi agent fits into the picture and how to make the "AI company" set up work.

All of the above developments motivated me to refresh and extend my vocabulary and understanding. 
So in this post I'll be going over 1) what are agents and most basic concepts related to them 2) how do they differ 
from standard chatbots 3) why multi agent approach and defining contracts is such a big deal 4) go over concrete example 
using CrewAI to explain how above mentioned concepts play together

## How agent differs from chatbot?

Well, this is a bit of an ill posed question but I think this is something that can be easily confused. 
Chatbots can be agentic. Chatbot is w use case while agent is solution paradigma. So there are agentic and 
non-agentic chatbots. The agentic systems are characterized by an ability to interact with the environment using tools.

Tool can be anything. From simple things like calculator (yes, they come in handy even for LLMs) 
to quite an advance like a web browser.

They allow for dynamic input that is not easy to "remember" and is usually not available in the input prompt. 
You can probably already see how having a web browser that will  return most up to date price for flight ticket 
for any date requested makes life of an LLM much easier

The problem is that even with amazing tools our LLM will still struggle with coming up with the idea to ask tool for this 
information (idea of Chain of thought will help us here but let's ignore it for now) in the first place and with an 
abundance of information provided to it. This is where the concept of multiple agents comes in with decomposition and 
orchestration

* **Definition of an agent**

  * Formalized as a Markov Decision Process (MDP) tuple $(\mathcal{S}, \mathcal{A}, T, R, \gamma)$, where $\mathcal{S}$ is the set of environment states, $\mathcal{A}$ the action space (including tool invocations), $T(s' \mid s,a)$ the transition kernel, $R(s,a)$ the reward function, and $\gamma\in[0,1)$ the discount factor — the agent’s goal is to learn a policy $\pi_\theta(a\mid s)$ that maximizes the expected return

```math
J(\pi_\theta) = \mathbb{E}_{\tau\sim\pi_\theta}\Bigl[\sum_{t=0}^\infty \gamma^t R(s_t,a_t)\Bigr].
```

This encapsulates the notions of perception (observations $o_t$), action (tool calls), reasoning (policy computation), and autonomy. 
  * **Key properties**

    1. **Goal-directed**: optimizes $J(\pi)$.
    2. **Perception**: maps raw inputs to internal states $o_t=O(s_t)$.
    3. **Action**: issues primitive and tool-based actions $a_t$.
    4. **Reasoning**: employs internal latent chains $z_{1:n}$ (e.g., chain of thought).
    5. **Autonomy**: operates in closed-loop without human step-by-step prompting.

* **Building blocks of an agent**

  * **ML model (e.g., LLM)**: parameterized policy $\pi_\theta(a\mid o)$ often pretrained then fine-tuned.
  * **Central decision-making**

    * **Instruction-based reasoning**: maximize $\log P_\theta(a\mid\text{instr},o)$.
    * **Logical framework**: integrates symbolic constraints (e.g., type systems, invariants).
  * **Orchestration layers** (cyclical sense–plan–act loop)

    1. **Assimilate information**: update memory/state $m_t = f(m_{t-1},o_t)$.
    2. **Internal reasoning**: generate latent steps $\{z_i\}$ via CoT or ToT.
    3. **Reasoning for action**: choose $a_t = \arg\max_a Q(m_t,a)$.
    4. **Planning & state maintenance**: hierarchical planning over time horizon $H$.
    5. **Prompt-engineering frameworks**: structure $\text{prompt}=(\text{goal}, \text{history}, \text{tools})$.
  * **Reasoning techniques**

    * **Chain of Thought (CoT)**
    * **Tree of Thoughts (ToT)**: explores a tree $\mathcal{T}$ of partial reasoning states $\{n\}$, using search to select optimal branch. 
    * **ReAct**: interleaves reasoning ($z$) and acting ($a$) within a single trajectory, enabling on-the-fly API/tool calls.

```math
        P(y,z∣x)=∏i=1∣z∣P(zi∣x,z<i)×P(y∣x,z) , P(y,z\mid x) = \prod_{i=1}^{|z|}P(z_i\mid x,z_{<i})\times P(y\mid x,z)\,,
```
where $z$ is the sequence of intermediate reasoning steps. CoT prompting elicits $z$ to improve complex reasoning accuracy.


* **Agent ops**

  * **Tool management**: dynamic registry $\mathcal{T}$, select $t\in\mathcal{T}$ based on context.
  * **Agent brain prompt**: structured tuple $(\text{goal}, \text{persona}, \text{instructions})$.
  * **Task decomposition**: high-level goal $\rightarrow$ subgoals $\{g_i\}$ solved by specialized modules.

* **Multi-agent aspect**

  * **Specialized agents collaboration**

    * **Team of experts**: decompose a complex task into subproblems $g_1,\dots,g_k$.
    * **Role-specific contexts**: agent $i$ has local state $s^i_t$ and policy $\pi^i$.
    * **Decentralized problem-solving**: global plan arises from local interactions over a communication graph $G$.
    * **Adaptive execution**: only activate subset $\{\pi^i\}$ relevant to current context.
    * **Explainability**: communication logs $\{m^i_t\}$ serve as audit trails.
  * **Advantages over single agent**

    1. **Accuracy & fault tolerance**: cross-checking among $\pi^i$.
    2. **Scalability**: parallel execution of $\{\pi^i\}$.
    3. **Complexity handling**: divide-and-conquer reduces combinatorial explosion.
    4. **Bias mitigation**: ensemble of perspectives.
  * **Components**

    1. **Cognitive functions**: self-correction, refinement, planning modules.
    2. **Tool integration**: dynamic tool registers, retrieval-augmented generation.
    3. **Flow/routing**: determine message paths in $G$.
    4. **Feedback loops / RL**: online updates of $\pi^i$ via reward signals.
    5. **Agent registry**: discover/register/instantiate agents on demand.

* **Agentic RAG**

  * **Retrieval-Augmented Generation (RAG)**: augments $\pi_\theta$ with external corpus $\mathcal{D}$ via a retriever $q_\phi$. For input $x$, retrieve $\{d_j\}\sim q_\phi(\cdot\mid x)$ then generate

```math
    P(y\mid x) = \sum_j P_\theta(y\mid x,d_j)\,P_\phi(d_j\mid x).
```

RAG improves factuality and up-to-date knowledge.

  * **Agentic RAG enhancements**

    * **Decomposed queries**: split $x$ into subqueries $\{x_i\}$.
    * **Dynamic source selection**: choose best $d_j$ per subquery.
    * **Evaluator agents**: verify consistency, correct hallucinations.
    * **Context-aware expansion**: iterative query refinement.

* **Enterprise**

  * **Agent types**

    * **Assistant**: user-facing, handles natural language tasks.
    * **Contractor**: fulfills well-defined outcomes under a “contract” $(\text{spec}, \text{metrics}, \text{SLAs})$.
    * **Manager**: oversees and delegates to contractors.
  * **Contracts**

    * Precisely define: scope, deliverables, validation tests.
    * Enable negotiation: resolve ambiguous requirements.
    * Govern subcontracting: enforce rules on downstream agents.
  * **Planner agent**: solves

```math
      \max_{\{g_i\}}\;U\bigl(\{\pi^j\bigl(g_i\bigr)\}\bigr)
```

  * **Retriever agent**: maintains dynamic index of live data.
  * **Execution agent**: performs actions / API calls.
  * **Evaluator agent**: computes validation metric $\delta(y,\hat y)$.

* **Evaluations**

  * **Agent success metrics**

    * **Goal completion rate**: $\text{GCR} = \frac{\text{tasks succeeded}}{\text{tasks attempted}}$.
    * **Critical task accuracy**: success on high-risk steps.
    * **Tool-call success**: fraction of successful tool invocations.
    * **Latency**: average response time per action.
  * **Capability benchmarks**

    * **BFCL**, **τ-bench** (tool calling), **PlanBench**, **AgentBench**, **DABStep**.
  * **Trajectory & tool-use**

    * Compare expected vs actual trajectory $\tau$:

      * **Exact match**: $\tau_{\text{pred}} = \tau_{\text{ref}}$.
      * **Order-insensitive**: set overlap metrics (precision/recall).
  * **Evaluating final response**

    * Automatic: BLEU, ROUGE, custom task metrics.
    * Subjective: human ratings.
    * LLM as judge: chain-of-thought critique models.
  * **Continuous improvement**: iterate on evaluation protocols.

* **Multiagent evals**

  * **Cooperation / coordination**: measure synergy score

```math
      \text{Synergy} = \frac{J(\{\pi^i\}) - \sum_i J(\pi^i)}{\sum_i J(\pi^i)}.
```

  * **Planning & task assignment**: evaluate how well the planner allocates subgoals to specialists.
  * **Agent utilization**: fraction of agents actively contributing per request.
  * **Emergent behaviors**: detect unanticipated shortcuts or failure modes.





## Example Output of CrewAI

* Had to use ChatGPT because open source chatbots (even LLama 3 100 mil (check what it was exactly in size)) failed due to missunderstanding 
output of website scrapping tools and failing to correct the error. Something that could be improve by adding validation LLM to the workflow but I was just playing
to get a bit of hand-on experience with this type of open source multi agent orchestration experience. Worked both with ChatGPT 4o and distilled versions of it. 
* Biggest pain point for me if I were to develop an AI application would be limited number of predefined tools e.g. scrapping. I was using recommended default products
that had free trial period but for someone doing it for longer period of time this might become major cost especially as number of users grows. Of course you can write
these tools yourself but making them work really well and handle all expections is a lot of work. I would say you are better of paying and focusing on improving your
core product. I think as this type of development become more mature higher competition will improve the situation. 

**Input**
```
** Welcome to Trip Planner Crew
-------------------------------

From where will you be traveling from?
Warsaw

What are the cities options you are interested in visiting?
Tokyo

What is the date range you are interested in traveling?
01.01.2025-01.10.2025     

What are some of yo
```

**Agentic workflow Output**
```
* 7-Day Tokyo Itinerary (January 1 - January 10, 2025)

** Overview
Tokyo, a vibrant metropolis, blends traditional culture with modernity, offering countless exciting places for food enthusiasts and anime lovers alike. This itinerary ensures an unforgettable experience with carefully selected activities, dining, and accommodation tailored to your interests.

*** Weather Forecast
- **Average Temperature**: 2°C to 10°C (36°F to 50°F)
- **Conditions**: Cool and dry, ideal for outdoor exploration and indoor dining.

---

** Day 1: Arrival in Tokyo (January 1)
- **Accommodation**: Shinjuku Granbell Hotel ($150 per night)
  - Reason: Centrally located, great amenities, and access to Shinjuku’s nightlife.
*** Schedule:
- **Arrive at Narita/Haneda Airport**
- **Check-in & Freshen Up**
- **Dinner**: Experience New Year's Osechi-ryori at **Sukiyabashi Jiro** (approx. $500) 🌟 - Known for its exceptional sushi.
- **Relax**: Explore the Shinjuku area and visit Omoide Yokocho for drinks.

---
...


** Packing Suggestions
- Layered clothing (thermal wear, sweaters, can be chilly)
- Comfortable walking shoes
- A medium-sized umbrella (January can be dry but still wise to have)
- Personal items such as toiletries and sufficient cash

---

** Budget Breakdown
- **Flights**: Approx. $600-$1,200 (round trip)
- **Accommodation**: $1,050 (7 nights x $150)
- **Meals**: $25 daily (approx. $175 total)
- **Transportation**: $60 total for metro/commutes.
- **Attractions**: Approx. $100 total for entry fees.
- **Total Estimated Budget**: $2,185 - $2,725

Enjoy your fantastic journey through Tokyo! Indulge in the food, soak in the anime culture, and immerse yourself in the rich history of Japan.
```


# My Thoughts

This will change the way people interact with unknown. No longer googling simple terms in search engines but ask agent to
understand complex situation and provide relevant response. There is an interesting point to be made about how changing informaiton environment impacts today's society. 
Types of mental tasks we peform are belived to improve our capabilities. There is a theory raise in [Amusing Ourselves to Death: Public Discourse in the Age of Show Business](https://www.amazon.com/Amusing-Ourselves-Death-Discourse-Business/dp/014303653X)
that tools that offload our brain from performing these tasks cause us to lose skills and make us stupid. Before internet main hardship was obtaining information. Contributing to persistance and creativity. Although when the internet age got into full swing
obtaining information was no longer a problem but reliability of this information became an issue. Suddenly next generations are faced with new types of challanges.
How to quickly filter and verify. This looks like a great motivation to exercise critical thinking skills and improve with how we decompose complex tasks
into simple queries to which web can provide relevant information. In the age of agentic AI that can digest complex tasks skills like task decompositon will be no longer
needed. Similarly low-level coding that was pushing humans to perform cognitively demanding task of "thinking like a machine" is no longer as common. Currently 
conventional coding might meet the same fate of become a specialist skill. What's interesting to me is not predicting how developments like vibe coding will fail but how 
its potential success can influence this skill evolution dynamic. Getting this power of generative AI seems like something that in positive scenario could empower
developers to build complete more emersive than before experiences without it being resource intensive. Creativity and high level thinking skills of artists even with limited level of technical skills
could become very precious and a huge driver for innovation. 

   
* future
    * long-term memory
    * agent communication protocols
    * from agents to contractors



