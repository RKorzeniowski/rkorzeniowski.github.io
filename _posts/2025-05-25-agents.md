# Why are Agents so Hot?

Agents are the hot topic of recent days? Why is that? The main use case for AI so far (at least till 2024 before chatbots 
got agentified with tools) was this type of assistant that helps you solve simple problems you throw at it. 
It is very knowledgeable but as soon as you ask it to do something that requires a bit of common sense and "googling" 
it fails miserably. Either making things up or providing inaccurate information. Let's take as an example trip planning

When asked to come up with itinerary with estimated budget for trip in a week we can expect AI will give us made up 
flights with price estimate unrelated to current price (and let's not dream about it finding best deal for us), 
types of attractions a list of most typical activities not necessarily available at the time of our trip and so on.
If we "digest it a little bit" and ask for specific season it will usually do a little better but still might recommend
things that were closed. I will later talk about how agentic approach addresses some of these issues.

More recently companies stated a goal of automating junior developers. Copilot etc. 
There was significant progress in this field. From AI having a hard time writing doc strings, 
through tests being written just based on test  docstring written by developer and interfaces and existing codebase, 
to most recently impressive improvements to existing algorithms and coming up with new ones EvolveAlpha [1](https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/). 
Last one being more about blend of evolutionary algorithms and ? but agentic concept that happened along the way and 
how they impacted the dynamic are still interesting.

Another interesting experiment was trying to Carnegie Mellon University was to build full fledge company with AI agents [2](https://the-agent-company.com/). Best models
didn't perform too well with best candidates being able to solve around 25% of given tasks but what I find most interesting are areas in which they struggled:
- Implicit understanding. When told to save results in a file with a “.docx” extension, the AI agents couldn’t make the logical leap that this meant creating a Microsoft Word document.
- Social skills and especially fluent collaboration.
- Web navigation, particularly dealing with pop-ups and complex user interfaces.
Above are easy for humans but we have to keep in mind that agents have a lot of advantages like being highly scalable, follow instructions well... or so people 
arguing for AI Agents say but in the study very human-like behavior emerged where: when faced with difficult tasks, the agents sometimes took shortcuts and then reported successful completion. 
While exposing limitations of current technology and brining expectation a bit more in-line with "everyone at work will be replaced by AI in a year" with AI integration
in the workplace that follows careful task selection, realistic expectations, and probably a good deal of human oversight we might soon experiencing the 6th wave of innovaiton in full swing [3](https://core.ac.uk/download/pdf/30907274.pdf).

Finally the most recent document released by Google proposing the concept of an independent "agentic contractor" 
and explaining how multi agent fits into the picture and how to make the "AI company" set up work.

All of the above developments motivated me to refresh and extend my vocabulary and understanding. 
So in this post I'll be going over 1) what are agents and most basic concepts related to them 2) how do they differ 
from standard chatbots 3) why multi agent approach and defining contracts is such a big deal 4) go over concrete example 
using CrewAI to explain how above mentioned concepts play together

## How Does Agent Differ from a Chatbot?

Well, this is a bit of an ill posed question but I think this is something that can be easily confused. 
Chatbots can be agentic. Chatbot is a use case while agent is solution paradigma. So there can be both agentic and 
non-agentic chatbots. The agentic systems are characterized by an ability to interact with the environment using tools.

Tool can be anything. From simple things like calculator (yes, they come in handy even for LLMs) 
to quite advanced onces like a web browser.

They allow for dynamic input that is not easy to "remember" and is usually not available in the input prompt. 
You can probably already see how having a web browser that will return most up to date price for flight ticket 
for any date requested makes life of an LLM much easier

The problem is that even with amazing tools our LLM will still struggle with coming up with the idea to ask tool for this 
information (idea of Chain of thought will help us here but let's ignore it for now) in the first place and with an 
abundance of information provided to it. This is where the concept of multiple agents comes in with decomposition and 
orchestration

The easiest way to understand ideas around agents would be explaining them as we encounter then with a concrete example and
this is exactly what next section is going to be about!

## Toy Example: BoardMaster

Let's harness the power of AI to solve one of the central problems of humanity - "Who is going to deal with being the 
game master during a family gathering. And even more importantly who is going to spend next 30 minutes trying to 
understand and explain the rules of this new board game one of you just got". To make the problem a bit more concreate and
easy to track mistakes that AI might make let's do it for Monopoly. While easy and entertaining for humans the process of
playing Monopoly requires quite advanced cognitive skills like tracking the state of the game, following the rules, 
communicating with other players. If we wanted to write a program it would be very challening. Furthermore it would be basically 
impossible to transfer quickly to a different game that structured differently but with the setup we are going to build it 
should only require updating a few variables. 

### Naked LLM

We went with `gpt-4.1-nano` since stronger LLMs can power through the problems with sheer size (probably can break it. Mb try first). 
(mb a few words on what it looks like)

There are tricks we can do to improve model performance like Chain of Thought but I don't want to
get distracted from agentic aspect so we keep our LLM vanilla in terms of test-time compute. If you are interested in this aspect
there is an amazing blog post by Lilian Wang ["Why we think"](https://lilianweng.github.io/posts/2025-05-01-thinking/) I recommend
checking out.

To not make the model completly stateless we implemented a class that keep track of all agent and players messages and prepends them
to each user query. This gives model relevant context to make the replies relevant.  

In this setup we are facing following issues 
- model making things up
- task too hard for simple LLM to follow all the aspects. 

### Let's get Agentic in Here

This is a perfect place to formally define what is an Agent

* **Definition of an agent**

  * Formalized as a Markov Decision Process (MDP) tuple $(\mathcal{S}, \mathcal{A}, T, R, \gamma)$, where
  *  $\mathcal{S}$ is the set of environment states, $\mathcal{A}$ the action space (including tool invocations), $T(s' \mid s,a)$ the transition kernel, $R(s,a)$ the reward function, and $\gamma\in[0,1)$ the discount factor — the agent’s goal is to learn a policy $\pi_\theta(a\mid s)$ that maximizes the expected return

```math
J(\pi_\theta) = \mathbb{E}_{\tau\sim\pi_\theta}\Bigl[\sum_{t=0}^\infty \gamma^t R(s_t,a_t)\Bigr].
```

This encapsulates the notions of perception (observations $o_t$), action (tool calls), reasoning (policy computation), and autonomy. 
  * **Key properties**

    1. **Goal-directed**: optimizes $J(\pi)$.
    2. **Perception**: maps raw inputs to internal states $o_t=O(s_t)$.
    3. **Action**: issues primitive and tool-based actions $a_t$.
    4. **Reasoning**: employs internal latent chains $z_{1:n}$ (e.g., chain of thought).
    5. **Autonomy**: operates in closed-loop without human step-by-step prompting.

* **Building blocks of an agent**

  * **ML model (e.g., LLM)**: parameterized policy $\pi_\theta(a\mid o)$ often pretrained then fine-tuned.
  * **Central decision-making**

    * **Instruction-based reasoning**: maximize $\log P_\theta(a\mid\text{instr},o)$.
    * **Logical framework**: integrates symbolic constraints (e.g., type systems, invariants).
  * **Orchestration layers** (cyclical sense–plan–act loop)

    1. **Assimilate information**: update memory/state $m_t = f(m_{t-1},o_t)$.
    2. **Internal reasoning**: generate latent steps $\{z_i\}$ via CoT or ToT.
    3. **Reasoning for action**: choose $a_t = \arg\max_a Q(m_t,a)$.
    4. **Planning & state maintenance**: hierarchical planning over time horizon $H$.
    5. **Prompt-engineering frameworks**: structure $\text{prompt}=(\text{goal}, \text{history}, \text{tools})$.


We are done with thoery so let's start adapting our LLM by adding tools into the mix. In our pipeline we add RAG web search tool that uses wikipedia-api and sentence embeddings 
with cosine similarirty of query and retrived documents to allow an LLM to search the web for relevant context.

* **Agentic RAG**

  * **Retrieval-Augmented Generation (RAG)**: augments $\pi_\theta$ with external corpus $\mathcal{D}$ via a retriever $q_\phi$. For input $x$, retrieve $\{d_j\}\sim q_\phi(\cdot\mid x)$ then generate

```math
    P(y\mid x) = \sum_j P_\theta(y\mid x,d_j)\,P_\phi(d_j\mid x).
```

RAG improves factuality and up-to-date knowledge.

  * **Agentic RAG enhancements**

    * **Decomposed queries**: split $x$ into subqueries $\{x_i\}$.
    * **Dynamic source selection**: choose best $d_j$ per subquery.
    * **Evaluator agents**: verify consistency, correct hallucinations.
    * **Context-aware expansion**: iterative query refinement.

[Example tool usage]

This helps us ground the model. Now instead of falling back to made up facts model is able to check what is the correct information.
This process where model is basing it's predictions on verified source is called grounding (kinda, make more presise).

While solving grounding problem our model is still facing the issue of task being quite complex. The agent in this setup is
- easy to cheat
- gets confused about the game state
- fails when game lasts longer

### Multi-Agentic Setup

To be able to modify our lone agent into an organization we need to understand basic terminiology about workflows involving 
multiple agents. Critical here are ways we orgnize effots of agents

* **Agent ops**

  * **Tool management**: dynamic registry $\mathcal{T}$, select $t\in\mathcal{T}$ based on context.
  * **Agent brain prompt**: structured tuple $(\text{goal}, \text{persona}, \text{instructions})$.
  * **Task decomposition**: high-level goal $\rightarrow$ subgoals $\{g_i\}$ solved by specialized modules.

* **Multi-agent aspect**

  * **Specialized agents collaboration**

    * **Team of experts**: decompose a complex task into subproblems $g_1,\dots,g_k$.
    * **Role-specific contexts**: agent $i$ has local state $s^i_t$ and policy $\pi^i$.
    * **Decentralized problem-solving**: global plan arises from local interactions over a communication graph $G$.
    * **Adaptive execution**: only activate subset $\{\pi^i\}$ relevant to current context.
    * **Explainability**: communication logs $\{m^i_t\}$ serve as audit trails.

  * **Advantages over single agent**
 
    1. **Accuracy & fault tolerance**: cross-checking among $\pi^i$.
    2. **Scalability**: parallel execution of $\{\pi^i\}$.
    3. **Complexity handling**: divide-and-conquer reduces combinatorial explosion.
    4. **Bias mitigation**: ensemble of perspectives.
  
  * **Components**

    1. **Cognitive functions**: self-correction, refinement, planning modules.
    2. **Tool integration**: dynamic tool registers, retrieval-augmented generation.
    3. **Flow/routing**: determine message paths in $G$.
    4. **Feedback loops / RL**: online updates of $\pi^i$ via reward signals.
    5. **Agent registry**: discover/register/instantiate agents on demand.

So what are we going to add at this stage?
- multiple agents with custom roles assigned to them
- orchiestration of thier efforts in different configurations

[Graph representing the solution]

Critical here is concept of task decompositon. While leading whole game was too hard for LLM when we provide helpers
that specilize in subtasks that provide required information to solve global task suddenly our LLM is able to handle
the task very well (rewrite). Above we can see a graph with all the relevant compoenents added that make the life of 
Game Master easier. Let's analize what types of agents are there and what is thier purpuse in the workflow. 

  * **Agent types**

    * **Assistant**: user-facing, handles natural language tasks.
    * **Contractor**: fulfills well-defined outcomes under a “contract” $(\text{spec}, \text{metrics}, \text{SLAs})$.
    * **Manager**: oversees and delegates to contractors.
  * **Contracts**

    * Precisely define: scope, deliverables, validation tests.
    * Enable negotiation: resolve ambiguous requirements.
    * Govern subcontracting: enforce rules on downstream agents.
  * **Planner agent**: solves

```math
      \max_{\{g_i\}}\;U\bigl(\{\pi^j\bigl(g_i\bigr)\}\bigr)
```

  * **Retriever agent**: maintains dynamic index of live data.
  * **Execution agent**: performs actions / API calls.
  * **Evaluator agent**: computes validation metric $\delta(y,\hat y)$.

[Example where GM allows invalid input, validator catches, gives hint and GM processes correctly]

Go in detials Self-Consistency, Self-Reflection based on above.

This simple example is still far from generic board game companion but it serve as a great problem for application of 
agentic concepts. For future work we could
- Try to make the agent game anostic.
- Come up with a way to teach the model "how to play a new game" only based on game manual.
- Give it common sense. Make it more robust to minor missunderstandings or being cheated.
- While not allowing invalid moves like "rolled 32" it still is making up landing fields that do not correspond to number
of fields traveled on the real monopoly board.

You can find all the code [here](https://github.com/RKorzeniowski/BoardMaster/tree/main).

# My Thoughts

This will change the way people interact with unknown. No longer googling simple terms in search engines but ask agent to
understand complex situation and provide relevant response. There is an interesting point to be made about how changing informaiton environment impacts today's society. 
Types of mental tasks we peform are belived to improve our capabilities. There is a theory raise in [Amusing Ourselves to Death: Public Discourse in the Age of Show Business](https://www.amazon.com/Amusing-Ourselves-Death-Discourse-Business/dp/014303653X)
that tools that offload our brain from performing these tasks cause us to lose skills and make us stupid. Before internet main hardship was obtaining information. Contributing to persistance and creativity. Although when the internet age got into full swing
obtaining information was no longer a problem but reliability of this information became an issue. Suddenly next generations are faced with new types of challanges.
How to quickly filter and verify. This looks like a great motivation to exercise critical thinking skills and improve with how we decompose complex tasks
into simple queries to which web can provide relevant information. In the age of agentic AI that can digest complex tasks skills like task decompositon will be no longer
needed. Similarly low-level coding that was pushing humans to perform cognitively demanding task of "thinking like a machine" is no longer as common. Currently 
conventional coding might meet the same fate of become a specialist skill. What's interesting to me is not predicting how developments like vibe coding will fail but how 
its potential success can influence this skill evolution dynamic. Getting this power of generative AI seems like something that in positive scenario could empower
developers to build complete more emersive than before experiences without it being resource intensive. Creativity and high level thinking skills of artists even with limited level of technical skills
could become very precious and a huge driver for innovation. 

   
* future
    * long-term memory
    * agent communication protocols
    * from agents to contractors



